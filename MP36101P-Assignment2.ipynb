{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import all required libraries. They are a lot but we will try a lot of algorithm so it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import time\n",
    "import numpy\n",
    "import os.path\n",
    "import urllib.request\n",
    "import sklearn.datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data set is not present in the filesystem, we download it and load it to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('data/'):\n",
    "    os.makedirs('data/')\n",
    "\n",
    "if not os.path.isdir('data/txt_sentoken'):\n",
    "    if not os.path.isfile('data/review_polarity.tar.gz'):\n",
    "        urllib.request.urlretrieve('http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz', filename='data/review_polarity.tar.gz')\n",
    "        file = tarfile.open(name='data/review_polarity.tar.gz')\n",
    "        file.extractall(path='data/')\n",
    "\n",
    "reviews_data = sklearn.datasets.load_files('data/txt_sentoken', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep 20% of the data as test set and we will use the rest 80% to train and validate the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_data_train, reviews_data_test, target_train, target_test = train_test_split(reviews_data.data,\n",
    "                                                                                    reviews_data.target,\n",
    "                                                                                    test_size=0.20,\n",
    "                                                                                    random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start testing out algorithms. We will begin with Naive Bayes, a good base for tf-idf variables.\n",
    "\n",
    "We are also keeping the best scoring parameters of each algorithm in a file for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Multinomial Naive Bayes results:\n",
      "Best score: 0.831875\n",
      "Best parameters: {'clf__fit_prior': False, 'tfidf__ngram_range': (1, 2), 'clf__alpha': 0.1}\n",
      "Time required: 58.015098 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.86      0.76      0.81       209\n",
      "        pos       0.77      0.86      0.81       191\n",
      "\n",
      "avg / total       0.82      0.81      0.81       400\n",
      "\n",
      "[[159  50]\n",
      " [ 26 165]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   50.6s finished\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline that performes the vectorization and then execute the ML algorithm\n",
    "reviews_classifier_NB = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                                  ('clf', MultinomialNB())])\n",
    "\n",
    "#Create a dictionary of algorithm parameters to try out\n",
    "parameters_NB = {'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "                 'clf__alpha': (0.00001, 0.0001, 0.001, 0.01, 0.1, 1),\n",
    "                 'clf__fit_prior': (True, False)}\n",
    "\n",
    "#Define a grid search object that will execute the pipeline for all parameter combinations\n",
    "gs_NB = GridSearchCV(reviews_classifier_NB, parameters_NB, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit the models to the data (and count time required)\n",
    "start_time = time.time()\n",
    "gs_NB = gs_NB.fit(reviews_data_train, target_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "#Print results\n",
    "print(\"Multinomial Naive Bayes results:\")\n",
    "print(\"Best score: %f\" % gs_NB.best_score_)\n",
    "print(\"Best parameters: %r\" % gs_NB.best_params_)\n",
    "print(\"Time required: %f seconds\" % elapsed_time)\n",
    "\n",
    "#We will use the test data to measure the performance\n",
    "target_predicted = gs_NB.predict(reviews_data_test)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names))\n",
    "print(metrics.confusion_matrix(target_test, target_predicted))\n",
    "\n",
    "#Output to file\n",
    "result_file = open('result.txt', 'a')\n",
    "print(\"Best score: %f\" % gs_NB.best_score_, file=result_file)\n",
    "print(\"Best parameters: %r\" % gs_NB.best_params_, file=result_file)\n",
    "print(elapsed_time, file=result_file)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names), file=result_file)\n",
    "print(metrics.confusion_matrix(target_test, target_predicted), file=result_file)\n",
    "print(\"=================================================\", file=result_file)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can proceed with some Support Vector Machine algorithms. We will start will the Linear Support Vector Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1736 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 28.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Machine results:\n",
      "Best score: 0.839375\n",
      "Best parameters: {'clf__max_iter': 100, 'clf__multi_class': 'ovr', 'clf__tol': 0.01, 'tfidf__ngram_range': (1, 1), 'clf__C': 1.2, 'clf__penalty': 'l2', 'clf__loss': 'hinge'}\n",
      "Time required: 1683.585500 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.85      0.86       209\n",
      "        pos       0.84      0.86      0.85       191\n",
      "\n",
      "avg / total       0.86      0.85      0.86       400\n",
      "\n",
      "[[177  32]\n",
      " [ 26 165]]\n",
      "Linear Support Vector Machine results:\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline that performes the vectorization and then execute the ML algorithm\n",
    "reviews_classifier_linearSVC = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                                         ('clf', LinearSVC())])\n",
    "\n",
    "#Create a dictionary of algorithm parameters to try out\n",
    "parameters_linearSVC = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "                   'clf__tol': (0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001),\n",
    "                   'clf__C': (0.8, 0.9, 1.0, 1.1, 1.2),\n",
    "                   'clf__loss': ('hinge', 'squared_hinge'),\n",
    "                   'clf__max_iter': (100, 1000, 10000),\n",
    "                   'clf__penalty': ('l2',),\n",
    "                   'clf__multi_class': ('ovr', 'crammer_singer')}\n",
    "\n",
    "#Define a grid search object that will execute the pipeline for all parameter combinations\n",
    "gs_linearSVC = GridSearchCV(reviews_classifier_linearSVC, parameters_linearSVC, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit the models to the data (and count time required)\n",
    "start_time = time.time()\n",
    "gs_linearSVC = gs_linearSVC.fit(reviews_data_train, target_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "#Print results\n",
    "print(\"Linear Support Vector Machine results:\")\n",
    "print(\"Best score: %f\" % gs_linearSVC.best_score_)\n",
    "print(\"Best parameters: %r\" % gs_linearSVC.best_params_)\n",
    "print(\"Time required: %f seconds\" % elapsed_time)\n",
    "\n",
    "#We will use the test data to measure the performance\n",
    "target_predicted = gs_linearSVC.predict(reviews_data_test)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names))\n",
    "print(metrics.confusion_matrix(target_test, target_predicted))\n",
    "\n",
    "#Output to file\n",
    "result_file = open('result.txt', 'a')\n",
    "print(\"Linear Support Vector Machine results:\")\n",
    "print(\"Best score: %f\" % gs_linearSVC.best_score_, file=result_file)\n",
    "print(\"Best parameters: %r\" % gs_linearSVC.best_params_, file=result_file)\n",
    "print(elapsed_time, file=result_file)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names), file=result_file)\n",
    "print(metrics.confusion_matrix(target_test, target_predicted), file=result_file)\n",
    "print(\"=================================================\", file=result_file)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try other kernels of the SVM. We will put different kernels in the parameter list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 12.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine results:\n",
      "Best score: 0.505625\n",
      "Best parameters: {'tfidf__ngram_range': (1, 1), 'clf__C': 0.8, 'clf__decision_function_shape': 'ovr', 'clf__kernel': 'poly', 'clf__tol': 0.1}\n",
      "Time required: 782.168875 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.00      0.00      0.00       209\n",
      "        pos       0.48      1.00      0.65       191\n",
      "\n",
      "avg / total       0.23      0.48      0.31       400\n",
      "\n",
      "[[  0 209]\n",
      " [  0 191]]\n",
      "Support Vector Machine results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline that performes the vectorization and then execute the ML algorithm\n",
    "reviews_classifier_SVC = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                                   ('clf', SVC())])\n",
    "\n",
    "#Create a dictionary of algorithm parameters to try out\n",
    "parameters_SVC = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'clf__C': (0.8, 0.9, 1.0, 1.1, 1.2),\n",
    "                  'clf__kernel': ('poly', 'rbf', 'sigmoid'),\n",
    "                  'clf__tol': (0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001),\n",
    "                  'clf__decision_function_shape': ('ovr', 'ovo')}\n",
    "\n",
    "#Define a grid search object that will execute the pipeline for all parameter combinations\n",
    "gs_SVC = GridSearchCV(reviews_classifier_SVC, parameters_SVC, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit the models to the data (and count time required)\n",
    "start_time = time.time()\n",
    "gs_SVC = gs_SVC.fit(reviews_data_train, target_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "#Print results\n",
    "print(\"Support Vector Machine results:\")\n",
    "print(\"Best score: %f\" % gs_SVC.best_score_)\n",
    "print(\"Best parameters: %r\" % gs_SVC.best_params_)\n",
    "print(\"Time required: %f seconds\" % elapsed_time)\n",
    "\n",
    "#We will use the test data to measure the performance\n",
    "target_predicted = gs_SVC.predict(reviews_data_test)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names))\n",
    "print(metrics.confusion_matrix(target_test, target_predicted))\n",
    "\n",
    "#Output to file\n",
    "result_file = open('result.txt', 'a')\n",
    "print(\"Support Vector Machine results:\")\n",
    "print(\"Best score: %f\" % gs_SVC.best_score_, file=result_file)\n",
    "print(\"Best parameters: %r\" % gs_SVC.best_params_, file=result_file)\n",
    "print(elapsed_time, file=result_file)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names), file=result_file)\n",
    "print(metrics.confusion_matrix(target_test, target_predicted), file=result_file)\n",
    "print(\"=================================================\", file=result_file)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying another family of algorithms, we proceed to the linear models.\n",
    "\n",
    "The Passive-Aggressive algorithm yields the follwing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1792 candidates, totalling 5376 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1736 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2386 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3136 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3986 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4936 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5376 out of 5376 | elapsed: 20.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passive Aggressive linear model results:\n",
      "Best score: 0.847500\n",
      "Best parameters: {'clf__shuffle': True, 'clf__fit_intercept': False, 'clf__loss': 'squared_hinge', 'tfidf__ngram_range': (1, 2), 'clf__C': 0.6, 'clf__n_iter': 5, 'clf__warm_start': False}\n",
      "Time required: 1227.384459 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.85      0.86       209\n",
      "        pos       0.84      0.87      0.86       191\n",
      "\n",
      "avg / total       0.86      0.86      0.86       400\n",
      "\n",
      "[[178  31]\n",
      " [ 25 166]]\n",
      "Passive Aggressive linear model results:\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline that performes the vectorization and then execute the ML algorithm\n",
    "reviews_classifier_PassiveAggressive = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                                                 ('clf', PassiveAggressiveClassifier())])\n",
    "\n",
    "#Create a dictionary of algorithm parameters to try out\n",
    "parameters_PassiveAggressive = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "                                'clf__C': (0.6, 0.8, 1, 1.2, 1.4, 1.6, 1.8, 2.),\n",
    "                                'clf__fit_intercept': (True, False),\n",
    "                                'clf__n_iter': (1, 2, 3, 5, 8, 13, 21),\n",
    "                                'clf__shuffle': (True, False),\n",
    "                                'clf__loss': ('hinge', 'squared_hinge'),\n",
    "                                'clf__warm_start': (True, False)}\n",
    "\n",
    "#Define a grid search object that will execute the pipeline for all parameter combinations\n",
    "gs_PassiveAggressive = GridSearchCV(reviews_classifier_PassiveAggressive, parameters_PassiveAggressive, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit the models to the data (and count time required)\n",
    "start_time = time.time()\n",
    "gs_PassiveAggressive = gs_PassiveAggressive.fit(reviews_data_train, target_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "#Print results\n",
    "print(\"Passive Aggressive linear model results:\")\n",
    "print(\"Best score: %f\" % gs_PassiveAggressive.best_score_)\n",
    "print(\"Best parameters: %r\" % gs_PassiveAggressive.best_params_)\n",
    "print(\"Time required: %f seconds\" % elapsed_time)\n",
    "\n",
    "#We will use the test data to measure the performance\n",
    "target_predicted = gs_PassiveAggressive.predict(reviews_data_test)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names))\n",
    "print(metrics.confusion_matrix(target_test, target_predicted))\n",
    "\n",
    "#Output to file\n",
    "result_file = open('result.txt', 'a')\n",
    "print(\"Passive Aggressive linear model results:\")\n",
    "print(\"Best score: %f\" % gs_PassiveAggressive.best_score_, file=result_file)\n",
    "print(\"Best parameters: %r\" % gs_PassiveAggressive.best_params_, file=result_file)\n",
    "print(elapsed_time, file=result_file)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names), file=result_file)\n",
    "print(metrics.confusion_matrix(target_test, target_predicted), file=result_file)\n",
    "print(\"=================================================\", file=result_file)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another member of the linear model is the Ridge algorithm. The results follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  4.4min finished\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ckaidos/git/M36101P-Assignment2/env/lib/python3.4/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge linear model results:\n",
      "Best score: 0.846250\n",
      "Best parameters: {'tfidf__ngram_range': (1, 2), 'clf__fit_intercept': False, 'clf__alpha': 0.01, 'clf__normalize': True, 'clf__tol': 0.001}\n",
      "Time required: 269.739924 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.85      0.87       209\n",
      "        pos       0.84      0.88      0.86       191\n",
      "\n",
      "avg / total       0.86      0.86      0.86       400\n",
      "\n",
      "[[177  32]\n",
      " [ 23 168]]\n",
      "Ridge linear model results:\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline that performes the vectorization and then execute the ML algorithm\n",
    "reviews_classifier_Ridge = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                                    ('clf', RidgeClassifier())])\n",
    "\n",
    "#Create a dictionary of algorithm parameters to try out\n",
    "parameters_Ridge = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "                    'clf__alpha': (0.00001, 0.0001, 0.001, 0.01, 0.1, 1.),\n",
    "                    'clf__fit_intercept': (True, False),\n",
    "                    'clf__normalize': (True, False),\n",
    "                    'clf__tol': (0.00001, 0.0001, 0.001, 0.01, 0.1, 1.)}\n",
    "\n",
    "#Define a grid search object that will execute the pipeline for all parameter combinations\n",
    "gs_Ridge = GridSearchCV(reviews_classifier_Ridge, parameters_Ridge, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit the models to the data (and count time required)\n",
    "start_time = time.time()\n",
    "gs_Ridge = gs_Ridge.fit(reviews_data_train, target_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "#Print results\n",
    "print(\"Ridge linear model results:\")\n",
    "print(\"Best score: %f\" % gs_Ridge.best_score_)\n",
    "print(\"Best parameters: %r\" % gs_Ridge.best_params_)\n",
    "print(\"Time required: %f seconds\" % elapsed_time)\n",
    "\n",
    "#We will use the test data to measure the performance\n",
    "target_predicted = gs_Ridge.predict(reviews_data_test)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names))\n",
    "print(metrics.confusion_matrix(target_test, target_predicted))\n",
    "\n",
    "#Output to file\n",
    "result_file = open('result.txt', 'a')\n",
    "print(\"Ridge linear model results:\")\n",
    "print(\"Best score: %f\" % gs_Ridge.best_score_, file=result_file)\n",
    "print(\"Best parameters: %r\" % gs_Ridge.best_params_, file=result_file)\n",
    "print(elapsed_time, file=result_file)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names), file=result_file)\n",
    "print(metrics.confusion_matrix(target_test, target_predicted), file=result_file)\n",
    "print(\"=================================================\", file=result_file)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another family of classifiers is the decision trees. We will give a go to such an algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Decision tree results:\n",
      "Best score: 0.646250\n",
      "Best parameters: {'tfidf__ngram_range': (1, 2), 'clf__criterion': 'entropy', 'clf__splitter': 'random', 'clf__max_features': None}\n",
      "Time required: 38.029461 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.62      0.60      0.61       209\n",
      "        pos       0.57      0.59      0.58       191\n",
      "\n",
      "avg / total       0.60      0.59      0.60       400\n",
      "\n",
      "[[125  84]\n",
      " [ 78 113]]\n",
      "Decision tree results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   23.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline that performes the vectorization and then execute the ML algorithm\n",
    "reviews_classifier_Decision_Tree = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                                             ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "#Create a dictionary of algorithm parameters to try out\n",
    "parameters_Decision_Tree = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "                            'clf__criterion': ('gini', 'entropy'),\n",
    "                            'clf__splitter': ('best', 'random'),\n",
    "                            'clf__max_features': (None, 'sqrt', 'log2')}\n",
    "\n",
    "#Define a grid search object that will execute the pipeline for all parameter combinations\n",
    "gs_Decision_Tree = GridSearchCV(reviews_classifier_Decision_Tree, parameters_Decision_Tree, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit the models to the data (and count time required)\n",
    "start_time = time.time()\n",
    "gs_Decision_Tree = gs_Decision_Tree.fit(reviews_data_train, target_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "#Print results\n",
    "print(\"Decision tree results:\")\n",
    "print(\"Best score: %f\" % gs_Decision_Tree.best_score_)\n",
    "print(\"Best parameters: %r\" % gs_Decision_Tree.best_params_)\n",
    "print(\"Time required: %f seconds\" % elapsed_time)\n",
    "\n",
    "#We will use the test data to measure the performance\n",
    "target_predicted = gs_Decision_Tree.predict(reviews_data_test)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names))\n",
    "print(metrics.confusion_matrix(target_test, target_predicted))\n",
    "\n",
    "#Output to file\n",
    "result_file = open('result.txt', 'a')\n",
    "print(\"Decision tree results:\")\n",
    "print(\"Best score: %f\" % gs_Decision_Tree.best_score_, file=result_file)\n",
    "print(\"Best parameters: %r\" % gs_Decision_Tree.best_params_, file=result_file)\n",
    "print(elapsed_time, file=result_file)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names), file=result_file)\n",
    "print(metrics.confusion_matrix(target_test, target_predicted), file=result_file)\n",
    "print(\"=================================================\", file=result_file)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will try an ensemble method. We will use many random trees and assess the performance of this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Ensemble extra trees results:\n",
      "Best score: 0.856875\n",
      "Best parameters: {'tfidf__ngram_range': (1, 2), 'clf__n_estimators': 10000}\n",
      "Time required: 6123.715922 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.86      0.92      0.89       209\n",
      "        pos       0.90      0.84      0.87       191\n",
      "\n",
      "avg / total       0.88      0.88      0.88       400\n",
      "\n",
      "[[192  17]\n",
      " [ 31 160]]\n",
      "Ensemble extra trees results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 90.4min finished\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline that performes the vectorization and then execute the ML algorithm\n",
    "reviews_classifier_ExtraTrees = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                                          ('clf', ExtraTreesClassifier())])\n",
    "\n",
    "#Create a dictionary of algorithm parameters to try out\n",
    "parameters_Extra_Trees = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "                          'clf__n_estimators': (10, 100, 1000, 10000, 100000)}\n",
    "\n",
    "#Define a grid search object that will execute the pipeline for all parameter combinations\n",
    "gs_ExtraTrees = GridSearchCV(reviews_classifier_ExtraTrees, parameters_Extra_Trees, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit the models to the data (and count time required)\n",
    "start_time = time.time()\n",
    "gs_ExtraTrees = gs_ExtraTrees.fit(reviews_data_train, target_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "#Print results\n",
    "print(\"Ensemble extra trees results:\")\n",
    "print(\"Best score: %f\" % gs_ExtraTrees.best_score_)\n",
    "print(\"Best parameters: %r\" % gs_ExtraTrees.best_params_)\n",
    "print(\"Time required: %f seconds\" % elapsed_time)\n",
    "\n",
    "#We will use the test data to measure the performance\n",
    "target_predicted = gs_ExtraTrees.predict(reviews_data_test)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names))\n",
    "print(metrics.confusion_matrix(target_test, target_predicted))\n",
    "\n",
    "#Output to file\n",
    "result_file = open('result.txt', 'a')\n",
    "print(\"Ensemble extra trees results:\")\n",
    "print(\"Best score: %f\" % gs_ExtraTrees.best_score_, file=result_file)\n",
    "print(\"Best parameters: %r\" % gs_ExtraTrees.best_params_, file=result_file)\n",
    "print(elapsed_time, file=result_file)\n",
    "print(metrics.classification_report(target_test, target_predicted, target_names=reviews_data.target_names), file=result_file)\n",
    "print(metrics.confusion_matrix(target_test, target_predicted), file=result_file)\n",
    "print(\"=================================================\", file=result_file)\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
